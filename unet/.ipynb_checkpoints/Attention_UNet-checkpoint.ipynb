{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from imutils import paths\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as keras\n",
    "#from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "\n",
    "\n",
    "#import skimage.io as io\n",
    "#import skimage.transform as trans\n",
    "\n",
    "#K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data'\n",
    "training_data_dir = os.path.join(root_dir, 'train/images')\n",
    "training_data_mask_dir = os.path.join(root_dir, 'train/masks')\n",
    "\n",
    "val_data_dir = os.path.join(root_dir, 'val/images')\n",
    "val_data_pred_dir = os.path.join(root_dir, 'val/predict')\n",
    "val_data_mask_dir = os.path.join(root_dir, 'val/masks')\n",
    "\n",
    "test_data_dir = os.path.join(root_dir, 'test/images')\n",
    "test_data_pred_dir = os.path.join(root_dir, 'test/predict')\n",
    "test_data_mask_dir = os.path.join(root_dir, 'test/masks')\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "    j = -jaccard_coef(y_true, y_pred)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData_rgb(img,mask):\n",
    "    for i in range(3):\n",
    "        mean = np.mean(img[:,:,i])  # mean for data centering\n",
    "        std = np.std(img[:,:,i])  # std for data normalization\n",
    "        img[:,:,i] -= mean\n",
    "        img[:,:,i] /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)  # mean for data centering\n",
    "    std = np.std(img)  # std for data normalization\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = normalizeData_rgb(img,mask)\n",
    "        yield (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = normalizeData_rgb(img,mask)\n",
    "        yield (img,mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define UNet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttentionUnetModel():\n",
    "    # 3 - RGB\n",
    "    inputs = Input((img_rows, img_cols, 3))\n",
    "    conv1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=jaccard_coef_loss, metrics=[jaccard_coef])\n",
    "    \n",
    "    #model.compile(optimizer=Adam(lr=1e-5), loss=\"binary_crossentropy\", metrics=[jaccard_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data generation\n",
    "data_gen_args = dict(\n",
    "#    samplewise_center = True,\n",
    "#    samplewise_std_normalization = True,\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "#Validation data generation\n",
    "data_val_gen_args = dict(\n",
    "    #samplewise_center = True,\n",
    "    #samplewise_std_normalization = True\n",
    "    )\n",
    "\n",
    "#Create UNet Model\n",
    "#model = FullUnetModel()\n",
    "#model = UnetModel()\n",
    "model = AttentionUnetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup generator\n",
    "batch_size = 3\n",
    "\n",
    "myGene = trainGenerator(batch_size,'data/train','images','masks',data_gen_args)\n",
    "myValGene = validationGenerator(batch_size,'data/val','images','masks',data_val_gen_args)\n",
    "\n",
    "#Setup Checkpoint to only capture best estimate\n",
    "model_checkpoint = ModelCheckpoint('attention_unet_lesion.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "#Enable tensorboard\n",
    "tensorBoard = TensorBoard(\n",
    "    log_dir='./logs', \n",
    "    histogram_freq=0, \n",
    "    batch_size=batch_size, \n",
    "    write_graph=True, \n",
    "    write_grads=False, \n",
    "    write_images=True, \n",
    "    embeddings_freq=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Train\n",
    "history = model.fit_generator(\n",
    "    myGene,\n",
    "    steps_per_epoch = 600, \n",
    "    epochs=100,\n",
    "    callbacks=[model_checkpoint,tensorBoard],\n",
    "    validation_data=myValGene,\n",
    "    validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue traing\n",
    "#Use initial_epoch \n",
    "\n",
    "history2 = model.fit_generator(\n",
    "    myGene,\n",
    "    steps_per_epoch = 1000, \n",
    "    epochs=200,\n",
    "    callbacks=[model_checkpoint,tensorBoard], \n",
    "    initial_epoch = 125,\n",
    "    validation_data=myValGene,\n",
    "    validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['jaccard_coef'])\n",
    "plt.plot(history.history['val_jaccard_coef'])\n",
    "plt.title('Coefficiency')\n",
    "plt.ylabel('Coefficiency')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.legend(['Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.legend(['Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\li_ni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "\n",
    "model = LeakyUnetModelBig()\n",
    "model.load_weights(\"unet_lesion.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Model in module keras.engine.training object:\n",
      "\n",
      "class Model(keras.engine.network.Network)\n",
      " |  Model(*args, **kwargs)\n",
      " |  \n",
      " |  The `Model` class adds training & evaluation routines to a `Network`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Model\n",
      " |      keras.engine.network.Network\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See [optimizers](/optimizers).\n",
      " |          loss: String (name of objective function) or objective function.\n",
      " |              See [losses](/losses).\n",
      " |              If the model has multiple outputs, you can use a different loss\n",
      " |              on each output by passing a dictionary or a list of losses.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model\n",
      " |              during training and testing.\n",
      " |              Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary,\n",
      " |              such as `metrics={'output_a': 'accuracy'}`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          **kwargs: When using the Theano/CNTK backends, these arguments\n",
      " |              are passed into `K.function`.\n",
      " |              When using the TensorFlow backend,\n",
      " |              these arguments are passed into `tf.Session.run`.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per evaluation step.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: if True, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)\n",
      " |      Trains the model for a given number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling.\n",
      " |          validation_data: tuple `(x_val, y_val)` or tuple\n",
      " |              `(x_val, y_val, val_sample_weights)` on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined.\n",
      " |          validation_steps: Only relevant if `steps_per_epoch`\n",
      " |              is specified. Total number of steps (batches of samples)\n",
      " |              to validate before stopping.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Trains the model on data generated batch-by-batch by a Python generator\n",
      " |      (or an instance of `Sequence`).\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |              (`keras.utils.Sequence`) object in order to avoid\n",
      " |              duplicate data when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single\n",
      " |              batch. Therefore, all arrays in this tuple must have the same\n",
      " |              length (equal to the size of this batch). Different batches may\n",
      " |              have different sizes. For example, the last batch of the epoch\n",
      " |              is commonly smaller than the others, if the size of the dataset\n",
      " |              is not divisible by the batch size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Integer.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to the number of samples of your dataset\n",
      " |              divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire data provided,\n",
      " |              as defined by `steps_per_epoch`.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_data: This can be either\n",
      " |              - a generator or a `Sequence` object for the validation data\n",
      " |              - tuple `(x_val, y_val)`\n",
      " |              - tuple `(x_val, y_val, val_sample_weights)`\n",
      " |              on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `validation_data` generator before stopping\n",
      " |              at the end of every epoch. It should typically\n",
      " |              be equal to the number of samples of your\n",
      " |              validation dataset divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only). This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples\n",
      " |              from an under-represented class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation\n",
      " |              relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      " |              the beginning of each epoch. Only used with instances\n",
      " |              of `Sequence` (`keras.utils.Sequence`).\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      def generate_arrays_from_file(path):\n",
      " |          while True:\n",
      " |              with open(path) as f:\n",
      " |                  for line in f:\n",
      " |                      # create numpy arrays of input data\n",
      " |                      # and labels, from each line in the file\n",
      " |                      x1, x2, y = process_line(line)\n",
      " |                      yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      " |      \n",
      " |      model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                          steps_per_epoch=10000, epochs=10)\n",
      " |      ```\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: The input data, as a Numpy array\n",
      " |              (or list of Numpy arrays if the model has multiple inputs).\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding batches of input samples\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: Maximum size for the generator queue.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: If `True`, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input samples, as a Numpy array.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |  \n",
      " |  test_on_batch(self, x, y, sample_weight=None)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  train_on_batch(self, x, y, sample_weight=None, class_weight=None)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |          class_weight: Optional dictionary mapping\n",
      " |              class indices (integers) to\n",
      " |              a weight (float) to apply to the model's loss for the samples\n",
      " |              from this class during training.\n",
      " |              This can be useful to tell the model to \"pay more attention\" to\n",
      " |              samples from an under-represented class.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  call(self, inputs, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      A model is callable on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      \n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)\n",
      " |      Loads all layer weights from a HDF5 save file.\n",
      " |      \n",
      " |      If `by_name` is False (default) weights are loaded\n",
      " |      based on the network's topology, meaning the architecture\n",
      " |      should be the same as when the weights were saved.\n",
      " |      Note that layers that don't have weights are not taken\n",
      " |      into account in the topological ordering, so adding or\n",
      " |      removing layers is fine as long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers\n",
      " |      only if they share the same name. This is useful\n",
      " |      for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the weights file to load.\n",
      " |          by_name: Boolean, whether to load weights by name\n",
      " |              or by topological order.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers\n",
      " |              where there is a mismatch in the number of weights,\n",
      " |              or a mismatch in the shape of the weight\n",
      " |              (only valid when `by_name`=True).\n",
      " |          reshape: Reshape weights to fit the layer when the correct number\n",
      " |              of weight arrays is present but their shape does not match.\n",
      " |      \n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  run_internal_graph(self, inputs, masks=None)\n",
      " |      Computes output tensors for new inputs.\n",
      " |      \n",
      " |      # Note:\n",
      " |          - Expects `inputs` to be a list (potentially with 1 element).\n",
      " |          - Can be run on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: List of tensors\n",
      " |          masks: List of masks (tensors or None).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Three lists: output_tensors, output_masks, output_shapes\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True)\n",
      " |      Saves the model to a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True)\n",
      " |      Dumps all layer weights to a HDF5 file.\n",
      " |      \n",
      " |      The weight file has:\n",
      " |          - `layer_names` (attribute), a list of strings\n",
      " |              (ordered names of model layers).\n",
      " |          - For every layer, a `group` named `layer.name`\n",
      " |              - For every such layer group, a group attribute `weight_names`,\n",
      " |                  a list of strings\n",
      " |                  (ordered names of weights tensor of the layer).\n",
      " |              - For every weight in the layer, a dataset\n",
      " |                  storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the model.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: A list of Numpy arrays with shapes and types matching\n",
      " |              the output of `model.get_weights()`.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |              It defaults to `print` (prints to stdout).\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A YAML string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A model instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the model's input specs.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  losses\n",
      " |      Retrieves the model's losses.\n",
      " |      \n",
      " |      Will only include losses that are either\n",
      " |      unconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include losses that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of loss tensors.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |      Retrieves the model's updates.\n",
      " |      \n",
      " |      Will only include updates that are either\n",
      " |      unconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include updates that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  uses_learning_phase\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\li_ni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_0000034.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\li_ni\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_0000054.jpg\n",
      "ISIC_0000058.jpg\n",
      "ISIC_0000060.jpg\n",
      "ISIC_0000064.jpg\n",
      "ISIC_0000079.jpg\n",
      "ISIC_0000081.jpg\n",
      "ISIC_0000112.jpg\n",
      "ISIC_0000117.jpg\n",
      "ISIC_0000128.jpg\n",
      "ISIC_0000137.jpg\n",
      "ISIC_0000172.jpg\n",
      "ISIC_0000184.jpg\n",
      "ISIC_0000207.jpg\n",
      "ISIC_0000219.jpg\n",
      "ISIC_0000222.jpg\n",
      "ISIC_0000224.jpg\n",
      "ISIC_0000228.jpg\n",
      "ISIC_0000262.jpg\n",
      "ISIC_0000269.jpg\n",
      "ISIC_0000274.jpg\n",
      "ISIC_0000277.jpg\n",
      "ISIC_0000279.jpg\n",
      "ISIC_0000299.jpg\n",
      "ISIC_0000310.jpg\n",
      "ISIC_0000331.jpg\n",
      "ISIC_0000336.jpg\n",
      "ISIC_0000349.jpg\n",
      "ISIC_0000350.jpg\n",
      "ISIC_0000357.jpg\n",
      "ISIC_0000361.jpg\n",
      "ISIC_0000363.jpg\n",
      "ISIC_0000376.jpg\n",
      "ISIC_0000383.jpg\n",
      "ISIC_0000425.jpg\n",
      "ISIC_0000426.jpg\n",
      "ISIC_0000470.jpg\n",
      "ISIC_0000479.jpg\n",
      "ISIC_0000482.jpg\n",
      "ISIC_0000487.jpg\n",
      "ISIC_0000490.jpg\n",
      "ISIC_0000513.jpg\n",
      "ISIC_0000519.jpg\n",
      "ISIC_0000520.jpg\n",
      "ISIC_0000900.jpg\n",
      "ISIC_0001103.jpg\n",
      "ISIC_0001163.jpg\n",
      "ISIC_0001385.jpg\n",
      "ISIC_0002093.jpg\n",
      "ISIC_0002353.jpg\n",
      "ISIC_0002780.jpg\n",
      "ISIC_0002871.jpg\n",
      "ISIC_0003005.jpg\n",
      "ISIC_0006114.jpg\n",
      "ISIC_0006350.jpg\n",
      "ISIC_0006711.jpg\n",
      "ISIC_0006776.jpg\n",
      "ISIC_0007156.jpg\n",
      "ISIC_0007788.jpg\n",
      "ISIC_0007796.jpg\n",
      "ISIC_0008116.jpg\n",
      "ISIC_0008280.jpg\n",
      "ISIC_0008528.jpg\n",
      "ISIC_0008785.jpg\n",
      "ISIC_0008998.jpg\n",
      "ISIC_0009583.jpg\n",
      "ISIC_0009873.jpg\n",
      "ISIC_0009883.jpg\n",
      "ISIC_0009914.jpg\n",
      "ISIC_0009927.jpg\n",
      "ISIC_0009939.jpg\n",
      "ISIC_0009951.jpg\n",
      "ISIC_0009958.jpg\n",
      "ISIC_0009975.jpg\n",
      "ISIC_0009977.jpg\n",
      "ISIC_0009990.jpg\n",
      "ISIC_0009992.jpg\n",
      "ISIC_0010011.jpg\n",
      "ISIC_0010025.jpg\n",
      "ISIC_0010029.jpg\n",
      "ISIC_0010041.jpg\n",
      "ISIC_0010042.jpg\n",
      "ISIC_0010054.jpg\n",
      "ISIC_0010066.jpg\n",
      "ISIC_0010077.jpg\n",
      "ISIC_0010102.jpg\n",
      "ISIC_0010184.jpg\n",
      "ISIC_0010186.jpg\n",
      "ISIC_0010201.jpg\n",
      "ISIC_0010215.jpg\n",
      "ISIC_0010228.jpg\n",
      "ISIC_0010231.jpg\n",
      "ISIC_0010233.jpg\n",
      "ISIC_0010241.jpg\n",
      "ISIC_0010256.jpg\n",
      "ISIC_0010262.jpg\n",
      "ISIC_0010264.jpg\n",
      "ISIC_0010326.jpg\n",
      "ISIC_0010330.jpg\n",
      "ISIC_0010341.jpg\n",
      "ISIC_0010361.jpg\n",
      "ISIC_0010380.jpg\n",
      "ISIC_0010382.jpg\n",
      "ISIC_0010441.jpg\n",
      "ISIC_0010445.jpg\n",
      "ISIC_0010448.jpg\n",
      "ISIC_0010466.jpg\n",
      "ISIC_0010475.jpg\n",
      "ISIC_0010490.jpg\n",
      "ISIC_0010494.jpg\n",
      "ISIC_0010557.jpg\n",
      "ISIC_0010562.jpg\n",
      "ISIC_0010570.jpg\n",
      "ISIC_0010854.jpg\n",
      "ISIC_0011085.jpg\n",
      "ISIC_0011115.jpg\n",
      "ISIC_0011158.jpg\n",
      "ISIC_0011166.jpg\n",
      "ISIC_0011169.jpg\n",
      "ISIC_0011208.jpg\n",
      "ISIC_0011225.jpg\n",
      "ISIC_0011295.jpg\n",
      "ISIC_0011322.jpg\n",
      "ISIC_0011338.jpg\n",
      "ISIC_0011339.jpg\n",
      "ISIC_0011345.jpg\n",
      "ISIC_0011361.jpg\n",
      "ISIC_0011362.jpg\n",
      "ISIC_0012086.jpg\n",
      "ISIC_0012116.jpg\n",
      "ISIC_0012127.jpg\n",
      "ISIC_0012151.jpg\n",
      "ISIC_0012156.jpg\n",
      "ISIC_0012160.jpg\n",
      "ISIC_0012182.jpg\n",
      "ISIC_0012203.jpg\n",
      "ISIC_0012207.jpg\n",
      "ISIC_0012208.jpg\n",
      "ISIC_0012223.jpg\n",
      "ISIC_0012248.jpg\n",
      "ISIC_0012356.jpg\n",
      "ISIC_0012376.jpg\n",
      "ISIC_0012381.jpg\n",
      "ISIC_0012413.jpg\n",
      "ISIC_0012442.jpg\n",
      "ISIC_0012473.jpg\n",
      "ISIC_0012478.jpg\n",
      "ISIC_0012487.jpg\n",
      "ISIC_0012551.jpg\n",
      "ISIC_0012653.jpg\n",
      "ISIC_0012656.jpg\n",
      "ISIC_0012671.jpg\n",
      "ISIC_0012835.jpg\n",
      "ISIC_0012883.jpg\n",
      "ISIC_0012891.jpg\n",
      "ISIC_0012898.jpg\n",
      "ISIC_0012911.jpg\n",
      "ISIC_0012949.jpg\n",
      "ISIC_0012988.jpg\n",
      "ISIC_0013044.jpg\n",
      "ISIC_0013073.jpg\n",
      "ISIC_0013087.jpg\n",
      "ISIC_0013106.jpg\n",
      "ISIC_0013128.jpg\n",
      "ISIC_0013169.jpg\n",
      "ISIC_0013196.jpg\n",
      "ISIC_0013197.jpg\n",
      "ISIC_0013207.jpg\n",
      "ISIC_0013227.jpg\n",
      "ISIC_0013229.jpg\n",
      "ISIC_0013269.jpg\n",
      "ISIC_0013274.jpg\n",
      "ISIC_0013275.jpg\n",
      "ISIC_0013356.jpg\n",
      "ISIC_0013360.jpg\n",
      "ISIC_0013365.jpg\n",
      "ISIC_0013378.jpg\n",
      "ISIC_0013414.jpg\n",
      "ISIC_0013455.jpg\n",
      "ISIC_0013518.jpg\n",
      "ISIC_0013565.jpg\n",
      "ISIC_0013580.jpg\n",
      "ISIC_0013585.jpg\n",
      "ISIC_0013621.jpg\n",
      "ISIC_0013626.jpg\n",
      "ISIC_0013636.jpg\n",
      "ISIC_0013651.jpg\n",
      "ISIC_0013667.jpg\n",
      "ISIC_0013670.jpg\n",
      "ISIC_0013689.jpg\n",
      "ISIC_0013733.jpg\n",
      "ISIC_0013748.jpg\n",
      "ISIC_0013775.jpg\n",
      "ISIC_0013796.jpg\n",
      "ISIC_0013802.jpg\n",
      "ISIC_0013806.jpg\n",
      "ISIC_0013830.jpg\n",
      "ISIC_0013861.jpg\n",
      "ISIC_0013897.jpg\n",
      "ISIC_0013918.jpg\n",
      "ISIC_0013982.jpg\n",
      "ISIC_0014073.jpg\n",
      "ISIC_0014157.jpg\n",
      "ISIC_0014181.jpg\n",
      "ISIC_0014217.jpg\n",
      "ISIC_0014233.jpg\n",
      "ISIC_0014248.jpg\n",
      "ISIC_0014253.jpg\n",
      "ISIC_0014273.jpg\n",
      "ISIC_0014289.jpg\n",
      "ISIC_0014324.jpg\n",
      "ISIC_0014331.jpg\n",
      "ISIC_0014361.jpg\n",
      "ISIC_0014365.jpg\n",
      "ISIC_0014366.jpg\n",
      "ISIC_0014438.jpg\n",
      "ISIC_0014489.jpg\n",
      "ISIC_0014525.jpg\n",
      "ISIC_0014585.jpg\n",
      "ISIC_0014609.jpg\n",
      "ISIC_0014625.jpg\n",
      "ISIC_0014688.jpg\n",
      "ISIC_0014694.jpg\n",
      "ISIC_0014713.jpg\n",
      "ISIC_0014716.jpg\n",
      "ISIC_0014760.jpg\n",
      "ISIC_0014770.jpg\n",
      "ISIC_0014783.jpg\n",
      "ISIC_0014806.jpg\n",
      "ISIC_0014818.jpg\n",
      "ISIC_0014825.jpg\n",
      "ISIC_0014830.jpg\n",
      "ISIC_0014835.jpg\n",
      "ISIC_0014867.jpg\n",
      "ISIC_0014883.jpg\n",
      "ISIC_0014968.jpg\n",
      "ISIC_0014969.jpg\n",
      "ISIC_0015003.jpg\n",
      "ISIC_0015016.jpg\n",
      "ISIC_0015019.jpg\n",
      "ISIC_0015037.jpg\n",
      "ISIC_0015040.jpg\n",
      "ISIC_0015078.jpg\n",
      "ISIC_0015113.jpg\n",
      "ISIC_0015118.jpg\n",
      "ISIC_0015133.jpg\n",
      "ISIC_0015167.jpg\n",
      "ISIC_0015226.jpg\n",
      "ISIC_0015250.jpg\n",
      "ISIC_0015254.jpg\n",
      "ISIC_0015353.jpg\n",
      "ISIC_0015411.jpg\n",
      "ISIC_0015419.jpg\n",
      "ISIC_0015627.jpg\n",
      "ISIC_0015951.jpg\n",
      "ISIC_0015952.jpg\n",
      "ISIC_0016023.jpg\n",
      "ISIC_0016028.jpg\n",
      "ISIC_0016043.jpg\n",
      "ISIC_0016060.jpg\n"
     ]
    }
   ],
   "source": [
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "\n",
    "model = UnetModel()\n",
    "model.load_weights(\"unet_lesion.hdf5\")\n",
    "\n",
    "\n",
    "for file in file_names:\n",
    "    print(file)\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    mean = np.mean(img)  # mean for data centering\n",
    "    std = np.std(img)  # std for data normalization\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    results = model.predict(img)\n",
    "\n",
    "    result_img = array_to_img(results[0] * 255 )\n",
    "    #plt.imshow(result_img)\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 1, 256, 256)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 32, 256, 256) 320         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 32, 256, 256) 9248        conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling2D) (None, 32, 128, 128) 0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 64, 128, 128) 18496       max_pooling2d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 64, 128, 128) 36928       conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 128, 64, 64)  73856       max_pooling2d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 128, 64, 64)  147584      conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling2D) (None, 128, 32, 32)  0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 256, 32, 32)  295168      max_pooling2d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 256, 32, 32)  590080      conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling2D) (None, 256, 16, 16)  0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 512, 16, 16)  1180160     max_pooling2d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 512, 16, 16)  2359808     conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_36 (UpSampling2D) (None, 512, 32, 32)  0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_36 (Merge)                (None, 768, 32, 32)  0           up_sampling2d_36[0][0]           \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 256, 32, 32)  1769728     merge_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 256, 32, 32)  590080      conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_37 (UpSampling2D) (None, 256, 64, 64)  0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_37 (Merge)                (None, 384, 64, 64)  0           up_sampling2d_37[0][0]           \n",
      "                                                                 conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 128, 64, 64)  442496      merge_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 128, 64, 64)  147584      conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_38 (UpSampling2D) (None, 128, 128, 128 0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_38 (Merge)                (None, 192, 128, 128 0           up_sampling2d_38[0][0]           \n",
      "                                                                 conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 64, 128, 128) 110656      merge_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 64, 128, 128) 36928       conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_39 (UpSampling2D) (None, 64, 256, 256) 0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_39 (Merge)                (None, 96, 256, 256) 0           up_sampling2d_39[0][0]           \n",
      "                                                                 conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 32, 256, 256) 27680       merge_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 256, 256) 9248        conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 1, 256, 256)  33          conv2d_206[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,846,081\n",
      "Trainable params: 7,846,081\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "image = file_names[0]\n",
    "fig = plt.figure()\n",
    "\n",
    "a = fig.add_subplot(1, 4, 1)\n",
    "imgplot = plt.imshow(load_img(os.path.join(test_data_dir,image)), shape = (256,256))\n",
    "a.set_title('Image')\n",
    "a.set_axis_off()\n",
    "\n",
    "a = fig.add_subplot(1, 4, 2)\n",
    "imgplot = plt.imshow(load_img(os.path.join(test_data_mask_dir,image.split('.')[0]+\"_segmentation.png\")), shape = (256,256))\n",
    "a.set_title('Mask')\n",
    "a.set_axis_off()\n",
    "\n",
    "a = fig.add_subplot(1, 4, 3)\n",
    "imgplot = plt.imshow(load_img(os.path.join(test_data_pred_dir,image.split('.')[0]+\"_predict.jpg\")), shape = (256,256))\n",
    "a.set_title('Prediction')\n",
    "a.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_e66lephant_output = model.output[:, 386]                          \n",
    "\n",
    "last_conv_layer = model.get_layer('block5_conv3')                         \n",
    "\n",
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]   \n",
    "\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))                              \n",
    "\n",
    "iterate = K.function([model.input],\n",
    "                     [pooled_grads, last_conv_layer.output[0]])           \n",
    "\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])                \n",
    "\n",
    "for i in range(512):                                                      \n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]             \n",
    "\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_207/Sigmoid:0' shape=(?, 1, 256, 256) dtype=float32>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Model in module keras.engine.training object:\n",
      "\n",
      "class Model(keras.engine.topology.Container)\n",
      " |  The `Model` class adds training & evaluation routines to a `Container`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Model\n",
      " |      keras.engine.topology.Container\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See [optimizers](/optimizers).\n",
      " |          loss: String (name of objective function) or objective function.\n",
      " |              See [losses](/losses).\n",
      " |              If the model has multiple outputs, you can use a different loss\n",
      " |              on each output by passing a dictionary or a list of losses.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model\n",
      " |              during training and testing.\n",
      " |              Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary,\n",
      " |              such as `metrics={'output_a': 'accuracy'}`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          **kwargs: When using the Theano/CNTK backends, these arguments\n",
      " |              are passed into `K.function`.\n",
      " |              When using the TensorFlow backend,\n",
      " |              these arguments are passed into `tf.Session.run`.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per evaluation step.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: if True, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling.\n",
      " |          validation_data: tuple `(x_val, y_val)` or tuple\n",
      " |              `(x_val, y_val, val_sample_weights)` on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined.\n",
      " |          validation_steps: Only relevant if `steps_per_epoch`\n",
      " |              is specified. Total number of steps (batches of samples)\n",
      " |              to validate before stopping.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Trains the model on data generated batch-by-batch by a Python generator or an instance of `Sequence`.\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |              (`keras.utils.Sequence`) object in order to avoid\n",
      " |              duplicate data when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single\n",
      " |              batch. Therefore, all arrays in this tuple must have the same\n",
      " |              length (equal to the size of this batch). Different batches may\n",
      " |              have different sizes. For example, the last batch of the epoch\n",
      " |              is commonly smaller than the others, if the size of the dataset\n",
      " |              is not divisible by the batch size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Integer.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to the number of samples of your dataset\n",
      " |              divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire data provided,\n",
      " |              as defined by `steps_per_epoch`.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_data: This can be either\n",
      " |              - a generator for the validation data\n",
      " |              - tuple `(x_val, y_val)`\n",
      " |              - tuple `(x_val, y_val, val_sample_weights)`\n",
      " |              on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `validation_data` generator before stopping\n",
      " |              at the end of every epoch. It should typically\n",
      " |              be equal to the number of samples of your\n",
      " |              validation dataset divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only). This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from an under-represented class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      " |              the beginning of each epoch. Only used with instances\n",
      " |              of `Sequence` (`keras.utils.Sequence`).\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |          def generate_arrays_from_file(path):\n",
      " |              while True:\n",
      " |                  with open(path) as f:\n",
      " |                      for line in f:\n",
      " |                          # create numpy arrays of input data\n",
      " |                          # and labels, from each line in the file\n",
      " |                          x1, x2, y = process_line(line)\n",
      " |                          yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      " |      \n",
      " |          model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                              steps_per_epoch=10000, epochs=10)\n",
      " |      ```\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: The input data, as a Numpy array\n",
      " |              (or list of Numpy arrays if the model has multiple outputs).\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding batches of input samples\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: Maximum size for the generator queue.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: If `True`, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input samples, as a Numpy array.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |  \n",
      " |  test_on_batch(self, x, y, sample_weight=None)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  train_on_batch(self, x, y, sample_weight=None, class_weight=None)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |          class_weight: Optional dictionary mapping\n",
      " |              class indices (integers) to\n",
      " |              a weight (float) to apply to the model's loss for the samples\n",
      " |              from this class during training.\n",
      " |              This can be useful to tell the model to \"pay more attention\" to\n",
      " |              samples from an under-represented class.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  __init__(self, inputs, outputs, name=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  call(self, inputs, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      A model is callable on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      \n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)\n",
      " |      Loads all layer weights from a HDF5 save file.\n",
      " |      \n",
      " |      If `by_name` is False (default) weights are loaded\n",
      " |      based on the network's topology, meaning the architecture\n",
      " |      should be the same as when the weights were saved.\n",
      " |      Note that layers that don't have weights are not taken\n",
      " |      into account in the topological ordering, so adding or\n",
      " |      removing layers is fine as long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers\n",
      " |      only if they share the same name. This is useful\n",
      " |      for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the weights file to load.\n",
      " |          by_name: Boolean, whether to load weights by name\n",
      " |              or by topological order.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers\n",
      " |              where there is a mismatch in the number of weights,\n",
      " |              or a mismatch in the shape of the weight\n",
      " |              (only valid when `by_name`=True).\n",
      " |          reshape: Reshape weights to fit the layer when the correct number\n",
      " |              of weight arrays is present but their shape does not match.\n",
      " |      \n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  run_internal_graph(self, inputs, masks=None)\n",
      " |      Computes output tensors for new inputs.\n",
      " |      \n",
      " |      # Note:\n",
      " |          - Expects `inputs` to be a list (potentially with 1 element).\n",
      " |          - Can be run on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: List of tensors\n",
      " |          masks: List of masks (tensors or None).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Three lists: output_tensors, output_masks, output_shapes\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True)\n",
      " |      Saves the model to a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True)\n",
      " |      Dumps all layer weights to a HDF5 file.\n",
      " |      \n",
      " |      The weight file has:\n",
      " |          - `layer_names` (attribute), a list of strings\n",
      " |              (ordered names of model layers).\n",
      " |          - For every layer, a `group` named `layer.name`\n",
      " |              - For every such layer group, a group attribute `weight_names`,\n",
      " |                  a list of strings\n",
      " |                  (ordered names of weights tensor of the layer).\n",
      " |              - For every weight in the layer, a dataset\n",
      " |                  storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the model.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: A list of Numpy arrays with shapes and types matching\n",
      " |              the output of `model.get_weights()`.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |              It defaults to `print` (prints to stdout).\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A YAML string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A model instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the model's input specs.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  losses\n",
      " |      Retrieves the model's losses.\n",
      " |      \n",
      " |      Will only include losses that are either\n",
      " |      inconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include losses that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of loss tensors.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |      Retrieves the model's updates.\n",
      " |      \n",
      " |      Will only include updates that are either\n",
      " |      inconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include updates that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  uses_learning_phase\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
